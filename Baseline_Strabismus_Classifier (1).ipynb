{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owuf9kVVy6sw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import cv2\n",
        "import os\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Constants\n",
        "IMG_SIZE = (224, 224)  # Standard size for CNN models\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "NUM_GAZE_IMAGES = 9  # Each sample consists of 9 images\n"
      ],
      "metadata": {
        "id": "BiLDBFM22XdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def split_9gaze_image(image, grid_size=(3, 3)):\n",
        "    \"\"\"Splits a single 9-gaze image into 9 individual images.\"\"\"\n",
        "    h, w, _ = image.shape\n",
        "    grid_h, grid_w = grid_size\n",
        "    img_h, img_w = h // grid_h, w // grid_w  # Calculate individual image dimensions\n",
        "\n",
        "    images = []\n",
        "    for i in range(grid_h):\n",
        "        for j in range(grid_w):\n",
        "            cropped_img = image[i * img_h:(i + 1) * img_h, j * img_w:(j + 1) * img_w]\n",
        "            images.append(cropped_img)\n",
        "\n",
        "    return images  # Returns a list of 9 images\n",
        "\n",
        "\n",
        "\n",
        "# Load Data\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []  # Modify based on dataset structure\n",
        "    for subject_folder in os.listdir(folder):  # Assuming each subject has a folder containing 9 images\n",
        "        subject_path = os.path.join(folder, subject_folder)\n",
        "        subject_images = []\n",
        "        if os.path.isdir(subject_path):\n",
        "            for filename in sorted(os.listdir(subject_path)):  # Ensure consistent order of images\n",
        "                img_path = os.path.join(subject_path, filename)\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is not None:\n",
        "                    img = cv2.resize(img, IMG_SIZE)\n",
        "                    img = img / 255.0  # Normalize\n",
        "                    subject_images.append(img)\n",
        "            if len(subject_images) == NUM_GAZE_IMAGES:\n",
        "                images.append(subject_images)\n",
        "                labels.append(0)  # Replace with actual labels\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "# define CNN Model for Multi-Image Input\n",
        "def baseline_model():\n",
        "    input_layer = layers.Input(shape=(NUM_GAZE_IMAGES, IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "\n",
        "    # Apply CNN to each image separately using TimeDistributed\n",
        "    base_cnn = keras.Sequential([\n",
        "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Conv2D(128, (3,3), activation='relu'),\n",
        "        layers.MaxPooling2D((2,2)),\n",
        "        layers.Flatten()\n",
        "    ])\n",
        "\n",
        "    cnn_features = layers.TimeDistributed(base_cnn)(input_layer)\n",
        "\n",
        "    # LSTM layer to capture sequential dependencies across 9-gaze images\n",
        "    lstm_layer = layers.LSTM(64, return_sequences=False)(cnn_features)\n",
        "\n",
        "    # Dense layers for final classification\n",
        "    dense_layer = layers.Dense(128, activation='relu')(lstm_layer)\n",
        "    dense_layer = layers.Dropout(0.5)(dense_layer)\n",
        "    output_layer = layers.Dense(1, activation='sigmoid')  # Binary classification\n",
        "\n",
        "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wqu199iU3PUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKsbGGOGOZMV",
        "outputId": "dac2ffb2-19ba-4acd-94b8-fe5f953396a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/AbnEye\")"
      ],
      "metadata": {
        "id": "f6HW35ldPNGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and Preprocess Data (Modify path)\n",
        "train_images, train_labels = load_images_from_folder(\"/content/drive/My Drive/AbnEye/train\")\n",
        "test_images, test_labels = load_images_from_folder(folder=\"/content/drive/My Drive/AbnEye/test\")\n",
        "\n",
        "# training Model\n",
        "model = baseline_model()\n",
        "model.fit(train_images, train_labels, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(test_images, test_labels))\n",
        "\n",
        "# Save Model\n",
        "model.save(\"strabismus_baseline_model.h5\")\n",
        "\n",
        "# Evaluate Model\n",
        "loss, acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "gexpm29tOdNP",
        "outputId": "ebad7a89-12ae-471a-de60-e0d0eea7122e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: 'train/image0.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-dd3604e633f7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load and Preprocess Data (Modify path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/image0.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images_from_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test/image0.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-fde3ed81e390>\u001b[0m in \u001b[0;36mload_images_from_folder\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Modify based on dataset structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msubject_folder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Assuming each subject has a folder containing 9 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msubject_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0msubject_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'train/image0.jpeg'"
          ]
        }
      ]
    }
  ]
}